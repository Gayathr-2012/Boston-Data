{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n\n# Introduction  Notebook\n\nEstaimted time needed: **10** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Acquire data in various ways\n*   Obtain insights from Data with Pandas library\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Table of Contents</h2>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><a href=\"https://#data_acquisition\">Data Acquisition</a>\n    <li><a href=\"https://#basic_insight\">Basic Insight of Dataset</a></li>\n</ol>\n\nEstimated Time Needed: <strong>10 min</strong>\n\n</div>\n<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h1 id=\"data_acquisition\">Data Acquisition</h1>\n<p>\nThere are various formats for a dataset, .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\nIn this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\nIn our case, the Automobile Dataset is an online source, and it is in CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n<ul>\n    <li>data source: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkST0151ENSkillsNetwork20531532-2022-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a></li>\n    <li>data type: csv</li>\n</ul>\nThe Pandas Library is a useful tool that enables us to read various datasets into a data frame; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing. If you run this notebook in a different environment, e.g. your desktop, you may need to uncomment and install Pandas or Numpy.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install(['numpy'],['pandas'])",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# import library\nimport pandas as pd\nimport numpy as np",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read Data</h2>\n<p>\nWe use <code>pandas.read_csv()</code> function to read the csv file. In the bracket, we put the file path along with a quotation mark, so that pandas will read the file into a data frame from that address. The file path can be either an URL or your local file address.<br>\nBecause the data does not include headers, we can add an argument <code>headers = None</code>  inside the  <code>read_csv()</code> method, so that pandas will not automatically set the first row as a header.<br>\nYou can also assign the dataset to any variable you create.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This dataset was hosted on IBM Cloud object click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkST0151ENSkillsNetwork20531532-2022-01-01\">HERE</a> for free storage.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from js import fetch\nimport io\n\nURL = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/auto.csv\"\nresp = await fetch(URL)\nother_path = io.BytesIO((await resp.arrayBuffer()).to_py())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Read the online file by the URL provides above, and assign it to variable \"df\"\ndf = pd.read_csv(other_path, header=None)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe; where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\") \ndf.head(5)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #1: </h1>\n<b>check the bottom 10 rows of data frame \"df\".</b>\n</div>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter\nfrom js import fetch\nimport io\nimport pandas as pd\n\nURL = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/auto.csv\"\nresp = await fetch(URL)\nother_path = io.BytesIO((await resp.arrayBuffer()).to_py())\ndf = pd.read_csv(other_path, header=None)\nprint(\"The last 10 rows of the dataframe\") \ndf.tail(10) ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The last 10 rows of the dataframe\n",
          "output_type": "stream"
        },
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     0    1      2       3      4     5      6    7      8      9   ...   16  \\\n195  -1   74  volvo     gas    std  four  wagon  rwd  front  104.3  ...  141   \n196  -2  103  volvo     gas    std  four  sedan  rwd  front  104.3  ...  141   \n197  -1   74  volvo     gas    std  four  wagon  rwd  front  104.3  ...  141   \n198  -2  103  volvo     gas  turbo  four  sedan  rwd  front  104.3  ...  130   \n199  -1   74  volvo     gas  turbo  four  wagon  rwd  front  104.3  ...  130   \n200  -1   95  volvo     gas    std  four  sedan  rwd  front  109.1  ...  141   \n201  -1   95  volvo     gas  turbo  four  sedan  rwd  front  109.1  ...  141   \n202  -1   95  volvo     gas    std  four  sedan  rwd  front  109.1  ...  173   \n203  -1   95  volvo  diesel  turbo  four  sedan  rwd  front  109.1  ...  145   \n204  -1   95  volvo     gas  turbo  four  sedan  rwd  front  109.1  ...  141   \n\n       17    18    19    20   21    22  23  24     25  \n195  mpfi  3.78  3.15   9.5  114  5400  23  28  13415  \n196  mpfi  3.78  3.15   9.5  114  5400  24  28  15985  \n197  mpfi  3.78  3.15   9.5  114  5400  24  28  16515  \n198  mpfi  3.62  3.15   7.5  162  5100  17  22  18420  \n199  mpfi  3.62  3.15   7.5  162  5100  17  22  18950  \n200  mpfi  3.78  3.15   9.5  114  5400  23  28  16845  \n201  mpfi  3.78  3.15   8.7  160  5300  19  25  19045  \n202  mpfi  3.58  2.87   8.8  134  5500  18  23  21485  \n203   idi  3.01  3.40  23.0  106  4800  26  27  22470  \n204  mpfi  3.78  3.15   9.5  114  5400  19  25  22625  \n\n[10 rows x 26 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>-1</td>\n      <td>74</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>four</td>\n      <td>wagon</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>104.3</td>\n      <td>...</td>\n      <td>141</td>\n      <td>mpfi</td>\n      <td>3.78</td>\n      <td>3.15</td>\n      <td>9.5</td>\n      <td>114</td>\n      <td>5400</td>\n      <td>23</td>\n      <td>28</td>\n      <td>13415</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>-2</td>\n      <td>103</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>104.3</td>\n      <td>...</td>\n      <td>141</td>\n      <td>mpfi</td>\n      <td>3.78</td>\n      <td>3.15</td>\n      <td>9.5</td>\n      <td>114</td>\n      <td>5400</td>\n      <td>24</td>\n      <td>28</td>\n      <td>15985</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>-1</td>\n      <td>74</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>four</td>\n      <td>wagon</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>104.3</td>\n      <td>...</td>\n      <td>141</td>\n      <td>mpfi</td>\n      <td>3.78</td>\n      <td>3.15</td>\n      <td>9.5</td>\n      <td>114</td>\n      <td>5400</td>\n      <td>24</td>\n      <td>28</td>\n      <td>16515</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>-2</td>\n      <td>103</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>turbo</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>104.3</td>\n      <td>...</td>\n      <td>130</td>\n      <td>mpfi</td>\n      <td>3.62</td>\n      <td>3.15</td>\n      <td>7.5</td>\n      <td>162</td>\n      <td>5100</td>\n      <td>17</td>\n      <td>22</td>\n      <td>18420</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>-1</td>\n      <td>74</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>turbo</td>\n      <td>four</td>\n      <td>wagon</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>104.3</td>\n      <td>...</td>\n      <td>130</td>\n      <td>mpfi</td>\n      <td>3.62</td>\n      <td>3.15</td>\n      <td>7.5</td>\n      <td>162</td>\n      <td>5100</td>\n      <td>17</td>\n      <td>22</td>\n      <td>18950</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>-1</td>\n      <td>95</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>109.1</td>\n      <td>...</td>\n      <td>141</td>\n      <td>mpfi</td>\n      <td>3.78</td>\n      <td>3.15</td>\n      <td>9.5</td>\n      <td>114</td>\n      <td>5400</td>\n      <td>23</td>\n      <td>28</td>\n      <td>16845</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>-1</td>\n      <td>95</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>turbo</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>109.1</td>\n      <td>...</td>\n      <td>141</td>\n      <td>mpfi</td>\n      <td>3.78</td>\n      <td>3.15</td>\n      <td>8.7</td>\n      <td>160</td>\n      <td>5300</td>\n      <td>19</td>\n      <td>25</td>\n      <td>19045</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>-1</td>\n      <td>95</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>109.1</td>\n      <td>...</td>\n      <td>173</td>\n      <td>mpfi</td>\n      <td>3.58</td>\n      <td>2.87</td>\n      <td>8.8</td>\n      <td>134</td>\n      <td>5500</td>\n      <td>18</td>\n      <td>23</td>\n      <td>21485</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>-1</td>\n      <td>95</td>\n      <td>volvo</td>\n      <td>diesel</td>\n      <td>turbo</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>109.1</td>\n      <td>...</td>\n      <td>145</td>\n      <td>idi</td>\n      <td>3.01</td>\n      <td>3.40</td>\n      <td>23.0</td>\n      <td>106</td>\n      <td>4800</td>\n      <td>26</td>\n      <td>27</td>\n      <td>22470</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>-1</td>\n      <td>95</td>\n      <td>volvo</td>\n      <td>gas</td>\n      <td>turbo</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>109.1</td>\n      <td>...</td>\n      <td>141</td>\n      <td>mpfi</td>\n      <td>3.78</td>\n      <td>3.15</td>\n      <td>9.5</td>\n      <td>114</td>\n      <td>5400</td>\n      <td>19</td>\n      <td>25</td>\n      <td>22625</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 26 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #1 Answer: </h1>\n<b>Run the code below for the solution!</b>\n</div>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Double-click <b>here</b> for the solution.\n\n<!-- The answer is below:\n\nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(10)\n\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h3>Add Headers</h3>\n<p>\nTake a look at our dataset; pandas automatically set the header by an integer from 0.\n</p>\n<p>\nTo better describe our data we can introduce a header, this information is available at:  <a href=\"https://archive.ics.uci.edu/ml/datasets/Automobile?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkST0151ENSkillsNetwork20531532-2022-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/datasets/Automobile</a>\n</p>\n<p>\nThus, we have to add headers manually.\n</p>\n<p>\nFirstly, we create a list \"headers\" that include all column names in order.\nThen, we use <code>dataframe.columns = headers</code> to replace the headers by the list we created.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# create headers list\nheaders = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\nprint(\"headers\\n\", headers)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We replace headers and recheck our data frame\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.columns = headers\ndf.head(10)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "we need to replace the \"?\" symbol with NaN so the dropna() can remove the missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df1=df.replace('?',np.NaN)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "we can drop missing values along the column \"price\" as follows\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df=df1.dropna(subset=[\"price\"], axis=0)\ndf.head(20)",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, we have successfully read the raw dataset and add the correct headers into the data frame.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #2: </h1>\n<b>Find the name of the columns of the dataframe</b>\n</div>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute \nfrom js import fetch\nimport io\nimport pandas as pd\n\nURL = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/auto.csv\"\nresp = await fetch(URL)\nother_path = io.BytesIO((await resp.arrayBuffer()).to_py())\n\n# Assuming 'other_path' is the path to your CSV file\ndf = pd.read_csv(other_path, header=None)\n\n# Display the column names\nprint(\"Column names of the DataFrame:\")\nprint(df.columns)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Column names of the DataFrame:\nInt64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n            17, 18, 19, 20, 21, 22, 23, 24, 25],\n           dtype='int64')\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "Double-click <b>here</b> for the solution.\n\n<!-- The answer is below:\n\nprint(df.columns)\n\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Save Dataset</h2>\n<p>\nCorrespondingly, Pandas enables us to save the dataset to csv  by using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n</p>\n<p>\n    For example, if you would save the dataframe <b>df</b> as <b>automobile.csv</b> to your local machine, you may use the syntax below:\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.to_csv(\"automobile.csv\", index=False)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can also read and save other file formats, we can use similar functions to **`pd.read_csv()`** and **`df.to_csv()`** for other data formats, the functions are listed in the following table:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read/Save Other Data Formats</h2>\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h1 id=\"basic_insight\">Basic Insight of Dataset</h1>\n<p>\nAfter reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\nThere are several ways to obtain essential insights of the data to help us better understand our dataset.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Data Types</h2>\n<p>\nData has a variety of types.<br>\nThe main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas: <code>dtypes</code> returns a Series with the data type of each column.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# check the data type of data frame \"df\" by .dtypes\nprint(df.dtypes)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<p>\nAs a result, as shown above, it is clear to see that the data type of \"symboling\" and \"curb-weight\" are <code>int64</code>, \"normalized-losses\" is <code>object</code>, and \"wheel-base\" is <code>float64</code>, etc.\n</p>\n<p>\nThese data types can be changed; If you want to learn more about data types or need more preparation before starting this course please visit:\n    <li>Coursera: <a href=\"https://www.coursera.org/learn/data-analysis-with-python?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkST0151ENSkillsNetwork20531532-2022-01-01#syllabus\" target=\"_blank\">https://www.coursera.org/learn/data-analysis-with-python#syllabus\n</a></li>\n    <li>CC.ai: <a href=\"https://cognitiveclass.ai/courses/data-analysis-python?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkST0151ENSkillsNetwork20531532-2022-01-01\" target=\"_blank\">https://cognitiveclass.ai/courses/data-analysis-python</a></li>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Describe</h2>\nIf we would like to get a statistical summary of each column, such as count, column mean value, column standard deviation, etc. We use the describe method:\n",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "dataframe.describe()",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.describe()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<p>\nThis shows the statistical summary of all numeric-typed (int, float) columns.<br>\nFor example, the attribute \"symboling\" has 205 counts, the mean value of this column is 0.83, the standard deviation is 1.25, the minimum value is -2, 25th percentile is 0, 50th percentile is 1, 75th percentile is 2, and the maximum value is 3.\n<br>\nHowever, what if we would also like to check all the columns including those that are of type object.\n<br><br>\n\nYou can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# describe all the columns in \"df\" \ndf.describe(include = \"all\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<p>\nNow, it provides the statistical summary of all the columns, including object-typed attributes.<br>\nWe can now see how many unique values, which is the top value and the frequency of top value in the object-typed columns.<br>\nSome values in the table above show as \"NaN\", this is because those numbers are not available regarding a particular column type.<br>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<p>\nYou can select the columns of a data frame by indicating the name of  each column, for example, you can select the three columns as follows:\n</p>\n<p>\n    <code>dataframe[['column 1', 'column 2', 'column 3']]</code>\n</p>\n<p>\nWhere \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n</p>\n<p>\n    <code>dataframe[['column 1', 'column 2', 'column 3']].describe()</code>\n</p>\n\nApply the  method to \".describe()\" to the columns 'length' and 'compression-ratio'.\n\n</div>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute \n\ndf[['length', 'compression-ratio']].describe()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'KeyError'>",
          "evalue": "\"None of [Index(['length', 'compression-ratio'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code below and press Shift+Enter to execute \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlength\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompression-ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['length', 'compression-ratio'], dtype='object')] are in the [columns]\""
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "Double-click <b>here</b> for the solution.\n\n<!-- The answer is below:\n\ndf[['length', 'compression-ratio']].describe()\n\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Info</h2>\nAnother method you can use to check your dataset is:\n",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "dataframe.info()",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "It provide a concise summary of your DataFrame.\n\nThis method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# look at the info of \"df\"\ndf.info()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<h1>Excellent! You have just completed the  Introduction  Notebook!</h1>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Thank you for completing this lab!\n\n## Author\n\n[Pratiksha Verma](https://www.linkedin.com/in/pratiksha-verma-6487561b1/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkST0151ENSkillsNetwork956-2022-01-01)\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By      | Change Description      |\n| ----------------- | ------- | -------------   | ----------------------- |\n| 2022-11-09        | 1.0     | Pratiksha Verma | Converted initial version to Jupyterlite|\n\n\n<hr>\n\n## <h3 align=\"center\"> IBM Corporation 2022. All rights reserved. <h3/>\n",
      "metadata": {}
    }
  ]
}